{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_11408\\2482454333.py:39: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Medline['T_A'] = Medline['T_A'].str.replace('\\d+', '')  # Remove numbers\n",
      "C:\\Temp\\ipykernel_11408\\2482454333.py:41: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Medline['T_A'] = Medline['T_A'].str.replace('[^a-zA-Z0-9]', ' ')  # Remove non-alphanumeric characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7785714285714286\n",
      "Confusion Matrix:\n",
      "[[165  29]\n",
      " [ 64 162]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pyreadr\n",
    "\n",
    "result = pyreadr.read_r('Diag_full.rds')\n",
    "Medline = result[None]\n",
    "\n",
    "\n",
    "# Select relevant columns and remove duplicates\n",
    "Medline = Medline[['PMID', 'T_A', 'diagnosis']]\n",
    "Medline = Medline.drop_duplicates()\n",
    "\n",
    "# Separate data into diagnosis and no diagnosis\n",
    "Medline_diag = Medline[Medline['diagnosis'] == 'Y']\n",
    "Medline_nodiag = Medline[Medline['diagnosis'] == 'N']\n",
    "\n",
    "# Set random seed and create training and test sets\n",
    "np.random.seed(42)\n",
    "Medline_train = pd.concat([Medline_diag[:500], Medline_nodiag[:500]])\n",
    "Medline_train = Medline_train.sample(frac=1)\n",
    "\n",
    "Medline_test = pd.concat([Medline_diag[500:700], Medline_nodiag[500:700]])\n",
    "Medline_test = Medline_test.sample(frac=1)\n",
    "\n",
    "Medline = pd.concat([Medline_train, Medline_test])\n",
    "\n",
    "# Normalize text for machine learning\n",
    "stop_words = [\"introduction\", \"conclusion\", \"objective\", \"aim\", \"methods\", \"results\", \"conclusions\",\n",
    "              \"background\", \"percent\", \"may\", \"use\", \"used\", \"however\", \"p\", \"cancer\", \"study\", \"lung\",\n",
    "              \"prostate\", \"prostatic\", \"patient\", \"colorectal\"]\n",
    "\n",
    "Medline['T_A'] = Medline['T_A'].str.replace('\\d+', '')  # Remove numbers\n",
    "Medline['T_A'] = Medline['T_A'].str.lower()  # Convert to lowercase\n",
    "Medline['T_A'] = Medline['T_A'].str.replace('[^a-zA-Z0-9]', ' ')  # Remove non-alphanumeric characters\n",
    "Medline['T_A'] = Medline['T_A'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(Medline['T_A'])\n",
    "\n",
    "# Encode the 'diagnosis' column\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Medline['diagnosis'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Set up the classifier (Support Vector Machine)\n",
    "classifier = SVC(probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: sample data (8 minutes)\n",
    "Let's see if we can increase the current accuracy\n",
    "What about if we increased the training data does that change the accuracy of the model?\n",
    "Let's change in #7. and #8. to\n",
    "0.64\n",
    "1. training 500, test 200 :0.64\n",
    "2. training 750, test 300 :0.68\n",
    "3. training 1000, test 400 :0.73\n",
    "4. training 1500, test 700 :0.70\n",
    "\n",
    "Which training size seems to give better accuracy?\n",
    "\n",
    "Let's add probabilities ##\n",
    "At the end of #6. add the following line of code to check the confidence of the algorithm towards their prediction\n",
    "learner$predict_type =\"prob\"\n",
    "\n",
    "Exercise 2: change the algorithm ## (8 minutes)\n",
    "mlr3 comes with the learner 'classif.rpart'(#6.), but we can change the algorithm to other learners using the mlr3learners package (https://github.com/mlr-org/mlr3learners)\n",
    "Try the following algorithms instead in #6.\n",
    "1. classif.svm 0.735\n",
    "2. classif.glmnet  0.7\n",
    "3. classif.ranger 0.77\n",
    "\n",
    "Others are available, you can try others if you have time...\n",
    "\n",
    "(if you get an error you may install a package as prompted... e.g. install.packages(\"ranger\"))\n",
    "\n",
    "Exercise 3: Let's change the balance of the data to see if it affects the predicition ## (15 minutes)\n",
    "\n",
    "In #2. let's see if an unbalanced vs. balanced dataset changes the accuracy of the model:\n",
    "\n",
    "Create 2 datasets, Medline_diag and Medline_nodiag by separating the diagnostics vs non_diagnostics cases (using filter)\n",
    "\n",
    "Then two datasets Medline_train and Medline_test with respectively: \n",
    "1. training --> nodiag: 700 diag: 300 | test --> nodiag: 200 diag: 200 --> 0.69\n",
    "2. training --> nodiag: 300 diag: 700 | test --> nodiag: 200 diag: 200 --> 0.66\n",
    "3. training --> nodiag: 500 diag: 500 | test --> nodiag: 200 diag: 200 --> 0.76\n",
    "\n",
    "To combine the training and the test set you can use the following code to help you:\n",
    "Medline_train <- bind_rows(Medline_diag[1:700,], Medline_nodiag[1:300,])\n",
    "\n",
    "when the training and test datasets have been done, don't forget to randomise the training dataset\n",
    "(e.g. Medline_train <- Medline_train[sample(nrow(Medline_train)),])\n",
    "\n",
    "And use bind_rows to join back the training and test set into Medline. \n",
    "\n",
    "Check how this affects the accuracy of the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
